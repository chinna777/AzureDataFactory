{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory name",
			"defaultValue": "sampleVenkeyAdf"
		},
		"AzureDataLakeStorage1_accountKey": {
			"type": "secureString",
			"metadata": "Secure string for 'accountKey' of 'AzureDataLakeStorage1'"
		},
		"AzureDataLakeStorage1_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://venkeyst.dfs.core.windows.net/"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/AzureDataLakeStorage1')]",
			"type": "Microsoft.DataFactory/factories/linkedServices",
			"apiVersion": "2018-06-01",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('AzureDataLakeStorage1_properties_typeProperties_url')]",
					"accountKey": {
						"type": "SecureString",
						"value": "[parameters('AzureDataLakeStorage1_accountKey')]"
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/DS_1')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureDataLakeStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": "Emp.csv",
						"fileSystem": "sample"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "Emp_id",
						"type": "String"
					},
					{
						"name": "Emp_name",
						"type": "String"
					},
					{
						"name": "Deptno",
						"type": "String"
					},
					{
						"name": "address",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/AzureDataLakeStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/DS_2')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureDataLakeStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": "department.csv",
						"fileSystem": "sample"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "deptno",
						"type": "String"
					},
					{
						"name": "department_name",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/AzureDataLakeStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/DS_Fruits')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureDataLakeStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": "fruits.csv",
						"fileSystem": "sample"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "id",
						"type": "String"
					},
					{
						"name": "vendor",
						"type": "String"
					},
					{
						"name": "apple",
						"type": "String"
					},
					{
						"name": "banana",
						"type": "String"
					},
					{
						"name": "mango",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/AzureDataLakeStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/DelimitedText1')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureDataLakeStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": "emp2.csv",
						"fileSystem": "sample"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "emp_id",
						"type": "String"
					},
					{
						"name": "emp_name",
						"type": "String"
					},
					{
						"name": "deptno",
						"type": "String"
					},
					{
						"name": "address",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/AzureDataLakeStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/Des_DS')]",
			"type": "Microsoft.DataFactory/factories/datasets",
			"apiVersion": "2018-06-01",
			"properties": {
				"linkedServiceName": {
					"referenceName": "AzureDataLakeStorage1",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileSystem": "sample"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "Emp_id",
						"type": "String"
					},
					{
						"name": "Emp_name",
						"type": "String"
					},
					{
						"name": "Deptno",
						"type": "String"
					},
					{
						"name": "address",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/linkedServices/AzureDataLakeStorage1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/Filter')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DS_1",
								"type": "DatasetReference"
							},
							"name": "source1"
						},
						{
							"dataset": {
								"referenceName": "DS_2",
								"type": "DatasetReference"
							},
							"name": "source2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Des_DS",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "ModifyColumns1",
							"description": "Autogenerated by data preview actions"
						},
						{
							"name": "ModifyColumns2",
							"description": "Autogenerated by data preview actions"
						},
						{
							"name": "join1"
						},
						{
							"name": "filter1"
						},
						{
							"name": "RemoveColumns2",
							"description": "Autogenerated by data preview actions"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Emp_id as string,",
						"          Emp_name as string,",
						"          Deptno as string,",
						"          address as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     limit: 100,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> source1",
						"source(output(",
						"          deptno as string,",
						"          department_name as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> source2",
						"source1 derive(Emp_name = trim(Emp_name,\"'\")) ~> ModifyColumns1",
						"ModifyColumns1 derive(address = upper(trim(address,\"'\"))) ~> ModifyColumns2",
						"ModifyColumns2, source2 join(source1@Deptno == source2@deptno,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"RemoveColumns2 filter(equals(Deptno,'10'),",
						"     partitionBy('hash', 1)) ~> filter1",
						"join1 select(mapColumn(",
						"          Emp_id,",
						"          Emp_name,",
						"          Deptno = source1@Deptno,",
						"          address,",
						"          department_name",
						"     ),",
						"     partitionBy('hash', 1),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> RemoveColumns2",
						"filter1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Emp_id as string,",
						"          Emp_name as string,",
						"          Deptno as string,",
						"          address as string",
						"     ),",
						"     partitionFileNames:['SingleDp.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/DS_1')]",
				"[concat(variables('factoryId'), '/datasets/DS_2')]",
				"[concat(variables('factoryId'), '/datasets/Des_DS')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow1')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DS_1",
								"type": "DatasetReference"
							},
							"name": "empdata",
							"description": "emp_data as source 1"
						},
						{
							"dataset": {
								"referenceName": "DS_2",
								"type": "DatasetReference"
							},
							"name": "deptdata",
							"description": "source2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Des_DS",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "ModifyColumns1",
							"description": "Autogenerated by data preview actions"
						},
						{
							"name": "ModifyColumns2",
							"description": "Autogenerated by data preview actions"
						},
						{
							"name": "innerjoin"
						},
						{
							"name": "select1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Emp_id as string,",
						"          Emp_name as string,",
						"          Deptno as string,",
						"          address as string",
						"     ),",
						"     allowSchemaDrift: false,",
						"     validateSchema: false,",
						"     limit: 10,",
						"     ignoreNoFilesFound: false) ~> empdata",
						"source(output(",
						"          deptno as string,",
						"          department_name as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     limit: 8,",
						"     ignoreNoFilesFound: false) ~> deptdata",
						"deptdata derive(department_name = upper(trim(department_name,\"'\"))) ~> ModifyColumns1",
						"empdata derive(Emp_name = trim(Emp_name,\"'\"),",
						"          address = trim(address,\"'\")) ~> ModifyColumns2",
						"ModifyColumns2, ModifyColumns1 join(empdata@Deptno == deptdata@deptno,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     partitionBy('hash', 1),",
						"     broadcast: 'auto')~> innerjoin",
						"innerjoin select(mapColumn(",
						"          Emp_id,",
						"          Emp_name,",
						"          Deptno = empdata@Deptno,",
						"          address,",
						"          department_name",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Emp_id as string,",
						"          Emp_name as string,",
						"          Deptno as string,",
						"          address as string",
						"     ),",
						"     partitionFileNames:['empDataT.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/DS_1')]",
				"[concat(variables('factoryId'), '/datasets/DS_2')]",
				"[concat(variables('factoryId'), '/datasets/Des_DS')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow_aggregate')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DS_1",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Des_DS",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "aggregate1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Emp_id as string,",
						"          Emp_name as string,",
						"          Deptno as string,",
						"          address as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> source1",
						"source1 aggregate(groupBy(Deptno),",
						"     EmpCount = count(Emp_name)) ~> aggregate1",
						"aggregate1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Emp_id as string,",
						"          Emp_name as string,",
						"          Deptno as string,",
						"          address as string",
						"     ),",
						"     partitionFileNames:['Agg.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/DS_1')]",
				"[concat(variables('factoryId'), '/datasets/Des_DS')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/exsists_doesnot')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DS_1",
								"type": "DatasetReference"
							},
							"name": "source1"
						},
						{
							"dataset": {
								"referenceName": "DS_2",
								"type": "DatasetReference"
							},
							"name": "source2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Des_DS",
								"type": "DatasetReference"
							},
							"name": "sink1"
						},
						{
							"dataset": {
								"referenceName": "Des_DS",
								"type": "DatasetReference"
							},
							"name": "sink2"
						}
					],
					"transformations": [
						{
							"name": "derivedColumn1"
						},
						{
							"name": "exists1"
						},
						{
							"name": "exists2"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Emp_id as string,",
						"          Emp_name as string,",
						"          Deptno as string,",
						"          address as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> source1",
						"source(output(",
						"          deptno as string,",
						"          department_name as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> source2",
						"source1 derive(Deptno = iif(equals(Deptno,\"10\"),replace(Deptno,\"10\", \"40\"),Deptno),",
						"     partitionBy('hash', 1)) ~> derivedColumn1",
						"derivedColumn1, source2 exists(derivedColumn1@Deptno == source2@deptno,",
						"     negate:false,",
						"     broadcast: 'auto')~> exists1",
						"derivedColumn1, source2 exists(derivedColumn1@Deptno == source2@deptno,",
						"     negate:true,",
						"     broadcast: 'auto')~> exists2",
						"exists1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Emp_id as string,",
						"          Emp_name as string,",
						"          Deptno as string,",
						"          address as string",
						"     ),",
						"     partitionFileNames:['exsisting.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1",
						"exists2 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Emp_id as string,",
						"          Emp_name as string,",
						"          Deptno as string,",
						"          address as string",
						"     ),",
						"     partitionFileNames:['doesnoExsists.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink2"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/DS_1')]",
				"[concat(variables('factoryId'), '/datasets/DS_2')]",
				"[concat(variables('factoryId'), '/datasets/Des_DS')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/lookup')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DS_1",
								"type": "DatasetReference"
							},
							"name": "source1"
						},
						{
							"dataset": {
								"referenceName": "DS_2",
								"type": "DatasetReference"
							},
							"name": "source2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Des_DS",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "lookup1"
						},
						{
							"name": "sort1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Emp_id as string,",
						"          Emp_name as string,",
						"          Deptno as string,",
						"          address as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> source1",
						"source(output(",
						"          deptno as string,",
						"          department_name as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> source2",
						"source1, source2 lookup(source1@Deptno == source2@deptno,",
						"     multiple: true,",
						"     broadcast: 'auto')~> lookup1",
						"lookup1 sort(desc(source1@Deptno, true),",
						"     caseInsensitive: true) ~> sort1",
						"sort1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Emp_id as string,",
						"          Emp_name as string,",
						"          Deptno as string,",
						"          address as string",
						"     ),",
						"     partitionFileNames:['llokup.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/DS_1')]",
				"[concat(variables('factoryId'), '/datasets/DS_2')]",
				"[concat(variables('factoryId'), '/datasets/Des_DS')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/split')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DS_1",
								"type": "DatasetReference"
							},
							"name": "source1"
						},
						{
							"dataset": {
								"referenceName": "DS_2",
								"type": "DatasetReference"
							},
							"name": "source2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Des_DS",
								"type": "DatasetReference"
							},
							"name": "sink1"
						},
						{
							"dataset": {
								"referenceName": "Des_DS",
								"type": "DatasetReference"
							},
							"name": "sink2"
						},
						{
							"dataset": {
								"referenceName": "Des_DS",
								"type": "DatasetReference"
							},
							"name": "sink3"
						}
					],
					"transformations": [
						{
							"name": "split1"
						},
						{
							"name": "join1"
						},
						{
							"name": "RemoveColumns1",
							"description": "Autogenerated by data preview actions"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Emp_id as string,",
						"          Emp_name as string,",
						"          Deptno as string,",
						"          address as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source(output(",
						"          deptno as string,",
						"          department_name as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> source2",
						"RemoveColumns1 split(equals(Deptno, '10'),",
						"     equals(Deptno,'20'),",
						"     equalsIgnoreCase(Deptno,'30'),",
						"     disjoint: false) ~> split1@(itStream, purchase, HRStream)",
						"source1, source2 join(source1@Deptno == source2@deptno,",
						"     joinType:'inner',",
						"     matchType:'exact',",
						"     ignoreSpaces: false,",
						"     broadcast: 'auto')~> join1",
						"join1 select(mapColumn(",
						"          Emp_id,",
						"          Emp_name,",
						"          Deptno = source1@Deptno,",
						"          address,",
						"          department_name",
						"     ),",
						"     partitionBy('hash', 1),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> RemoveColumns1",
						"split1@itStream sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Emp_id as string,",
						"          Emp_name as string,",
						"          Deptno as string,",
						"          address as string",
						"     ),",
						"     partitionFileNames:['itDept.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1",
						"split1@purchase sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Emp_id as string,",
						"          Emp_name as string,",
						"          Deptno as string,",
						"          address as string",
						"     ),",
						"     partitionFileNames:['purchase.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink2",
						"split1@HRStream sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Emp_id as string,",
						"          Emp_name as string,",
						"          Deptno as string,",
						"          address as string",
						"     ),",
						"     partitionFileNames:['HrDept.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink3"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/DS_1')]",
				"[concat(variables('factoryId'), '/datasets/DS_2')]",
				"[concat(variables('factoryId'), '/datasets/Des_DS')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/union')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DS_1",
								"type": "DatasetReference"
							},
							"name": "source1"
						},
						{
							"dataset": {
								"referenceName": "DelimitedText1",
								"type": "DatasetReference"
							},
							"name": "source2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Des_DS",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "union1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Emp_id as string,",
						"          Emp_name as string,",
						"          Deptno as string,",
						"          address as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> source1",
						"source(output(",
						"          emp_id as string,",
						"          emp_name as string,",
						"          deptno as string,",
						"          address as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> source2",
						"source1, source2 union(byName: true,",
						"     partitionBy('hash', 1))~> union1",
						"union1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Emp_id as string,",
						"          Emp_name as string,",
						"          Deptno as string,",
						"          address as string",
						"     ),",
						"     partitionFileNames:['FullEmp.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/DS_1')]",
				"[concat(variables('factoryId'), '/datasets/DelimitedText1')]",
				"[concat(variables('factoryId'), '/datasets/Des_DS')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/unpivot')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DS_Fruits",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Des_DS",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "unpivot1"
						},
						{
							"name": "aggregate1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          id as string,",
						"          vendor as string,",
						"          apple as string,",
						"          banana as string,",
						"          mango as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> source1",
						"source1 unpivot(output(",
						"          fruits as string,",
						"          Total as string",
						"     ),",
						"     ungroupBy(id,",
						"          vendor),",
						"     lateral: true,",
						"     ignoreNullPivots: false) ~> unpivot1",
						"unpivot1 aggregate(groupBy(fruits,",
						"          vendor),",
						"     indiv_count = count(fruits)) ~> aggregate1",
						"aggregate1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Emp_id as string,",
						"          Emp_name as string,",
						"          Deptno as string,",
						"          address as string",
						"     ),",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/DS_Fruits')]",
				"[concat(variables('factoryId'), '/datasets/Des_DS')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/window')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "DS_1",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "Des_DS",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "window1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          Emp_id as short,",
						"          Emp_name as string,",
						"          Deptno as short,",
						"          address as string,",
						"          salary as short",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false,",
						"     partitionBy('hash', 1)) ~> source1",
						"source1 window(over(Deptno),",
						"     desc(salary, true),",
						"     rank2 = denseRank()) ~> window1",
						"window1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Emp_id as string,",
						"          Emp_name as string,",
						"          Deptno as string,",
						"          address as string",
						"     ),",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> sink1"
					]
				}
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/datasets/DS_1')]",
				"[concat(variables('factoryId'), '/datasets/Des_DS')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/agg_pipe')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "dataflow_aggregate",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "dataflow_aggregate",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"source1": {},
									"sink1": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					},
					{
						"name": "Set variable1",
						"type": "SetVariable",
						"dependsOn": [
							{
								"activity": "dataflow_aggregate",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"variableName": "DAnny",
							"value": {
								"value": "@pipeline().Pipeline",
								"type": "Expression"
							}
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"variables": {
					"DAnny": {
						"type": "String",
						"defaultValue": "danny"
					}
				},
				"annotations": [],
				"lastPublishTime": "2022-11-01T10:38:38Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/dataflow_aggregate')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/exsists')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "exsists_doesnot",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "exsists_doesnot",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"source1": {},
									"source2": {},
									"sink1": {},
									"sink2": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": [],
				"lastPublishTime": "2022-11-01T11:54:55Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/exsists_doesnot')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline_filter')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Filter",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "Filter",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"source1": {},
									"source2": {},
									"sink1": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": [],
				"lastPublishTime": "2022-11-01T10:13:34Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/Filter')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline_split')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "split",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "split",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"source1": {},
									"source2": {},
									"sink1": {},
									"sink2": {},
									"sink3": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": [],
				"lastPublishTime": "2022-11-01T11:43:49Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/split')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/sample_lookup_sort')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "lookup",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "lookup",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"source1": {},
									"source2": {},
									"sink1": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": [],
				"lastPublishTime": "2022-11-01T12:21:10Z"
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/lookup')]"
			]
		}
	]
}